{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a84338-e6b6-49a6-b96c-58b326d45769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f224712-6d5c-4774-a631-173d3ab71923",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf730e5f-5914-406f-95d6-65af0d9f6af1",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24585dc0-8108-4f9b-b926-9fbec430c822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         text\n",
      "target                       \n",
      "airline_corpus            644\n",
      "brown_university_corpus   644\n"
     ]
    }
   ],
   "source": [
    "\"\"\" parameters:\n",
    "        input_path (str): path of CSV file to be read  \n",
    "        output_path (str): path of cleaned CSV file to write to\n",
    "\"\"\"\n",
    "\n",
    "def clean_csv(input_path, output_path):\n",
    "    input_dict = []\n",
    "\n",
    "    with open(input_path) as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader, None) #Skip header\n",
    "        for line in reader:\n",
    "            input_dict.append(json.loads(line[0])) #Read in each line as json\n",
    "        file.close()\n",
    "\n",
    "    data = pd.DataFrame.from_dict(input_dict)\n",
    "    data = data.replace(r'^\\s*$', np.nan, regex=True) #Catch single space error\n",
    "    data = data.dropna(how='any',axis=0)\n",
    "    print(data.groupby(\"target\").count())\n",
    "    data.to_csv(output_path)    \n",
    "    \n",
    "    \n",
    "clean_csv('./take_home_dataset.csv', './cleaned-dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ec238-1b23-4bc2-924c-dd4166ae9d2e",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca678b1-479e-404b-a231-6610a94ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "from indico import IndicoClient, IndicoConfig\n",
    "from indico.queries import ModelGroupPredict, JobStatus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26566c7-a87d-41ef-8b4c-83e49836ef41",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0154c341-46f3-48c2-bacb-02c3934c7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" parameters:\n",
    "        dataset (list): test data to be read into model\n",
    "        model_id (int): represents which model to use\n",
    "    returns: \n",
    "        predictions (list): predicted classifications generated by model\n",
    "\"\"\"\n",
    "\n",
    "def get_predictions(dataset, model_id):\n",
    "    my_config = IndicoConfig(\n",
    "        host=\"try.indico.io\", api_token_path=\"./indico_api_token.txt\"\n",
    "    )\n",
    "    client = IndicoClient(config=my_config)\n",
    "\n",
    "    # predict on the model\n",
    "    job = client.call(\n",
    "        ModelGroupPredict(\n",
    "            model_id=model_id,\n",
    "            data=dataset,\n",
    "            load=False\n",
    "        )\n",
    "    )\n",
    "    # retrieve your prediction results\n",
    "    predictions_dict = client.call(JobStatus(id=job.id, wait=True)).result\n",
    "\n",
    "    predictions = []\n",
    "    for pred in predictions_dict:\n",
    "        predictions.append(max(pred, key=pred.get))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9ec274-cf07-4aad-887b-0d1c5738192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" parameters:\n",
    "        truth (list): correct classifications provided in original dataset \n",
    "        predictions (list): predicted classifications generated by model\n",
    "    returns:\n",
    "        accuracy of predictions (float)\n",
    "\"\"\"\n",
    "\n",
    "def check_accuracy(truth, predictions):\n",
    "    correct_entries = 0 \n",
    "    for i in range(len(truth)):\n",
    "        if truth[i] == predictions[i]:\n",
    "            correct_entries += 1\n",
    "    return correct_entries/len(truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a6cd8-b70d-4a36-a4c7-16f07341aae5",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2f3db7-dae0-4870-b191-ab7ca6dff3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions are 98.52% accurate\n"
     ]
    }
   ],
   "source": [
    "input_data = pd.read_csv('./cleaned-dataset.csv')\n",
    "predictions = get_predictions(input_data['text'].tolist(), 2103)\n",
    "percent_correct = check_accuracy(input_data['target'], predictions)\n",
    "print('Model predictions are {:.2%} accurate'.format(percent_correct)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
